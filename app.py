import os
import random
import fitz  # PyMuPDF
import openai
from flask import Flask, render_template
from telegram import Update
from telegram.ext import ApplicationBuilder, ContextTypes, MessageHandler, filters
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import threading
import re
import asyncio

# --- Flask App ---
flask_app = Flask(__name__)

# --- OpenAI API ---
openai.api_key = os.getenv("OPENAI_API_KEY")
OPENAI_MODEL = "gpt-4-turbo"

# --- TÃ¡ch tá»«ng tÃ¬nh huá»‘ng theo sá»‘ thá»© tá»± ---
def extract_cases_by_structure(path):
    doc = fitz.open(path)
    full_text = "\n".join([page.get_text() for page in doc])
    pattern = r'\n\d{1,2}\.\s'
    parts = re.split(pattern, full_text)
    headers = re.findall(r'\n\d{1,2}\.\s', full_text)
    cases = []
    for i, part in enumerate(parts[1:], start=1):
        header = headers[i-1].strip()
        case_text = f"{header} {part}".strip()
        cases.append(case_text)
    return cases

# --- Load dá»¯ liá»‡u ---
chunks = extract_cases_by_structure("tinh_huong_khan_cap.pdf")
vectorizer = TfidfVectorizer()
chunk_vectors = vectorizer.fit_transform(chunks)

# --- Chá»n 1 tÃ¬nh huá»‘ng báº¥t ká»³ ---
def pick_random_scenario():
    return random.choice(chunks)

# --- TÃ¬m cÃ¡c Ä‘oáº¡n liÃªn quan Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ pháº£n há»“i ---
def search_relevant_chunks(text, top_n=3):
    vec = vectorizer.transform([text])
    sims = cosine_similarity(vec, chunk_vectors).flatten()
    top_ids = sims.argsort()[-top_n:][::-1]
    return [chunks[i] for i in top_ids]

# --- PhÃ¢n tÃ­ch pháº£n há»“i cá»§a há»c viÃªn ---
def analyze_response(user_answer, scenario_text):
    context_chunks = search_relevant_chunks(scenario_text)
    prompt = f"""
Báº¡n lÃ  trá»£ lÃ½ Ä‘Ã o táº¡o Ä‘iá»u dÆ°á»¡ng. HÃ£y Ä‘Ã¡nh giÃ¡ pháº£n há»“i cá»§a há»c viÃªn dá»±a trÃªn tÃ¬nh huá»‘ng kháº©n cáº¥p vÃ  tÃ i liá»‡u hÆ°á»›ng dáº«n. HÃ£y pháº£n há»“i theo cáº¥u trÃºc sau:

1. **CÃ¢u tráº£ lá»i cÃ³ phÃ¹ há»£p khÃ´ng?**
2. **Náº¿u chÆ°a Ä‘Ãºng thÃ¬ sai á»Ÿ Ä‘Ã¢u?**
3. **Gá»£i Ã½ vÃ  lÆ°u Ã½ thÃªm cho há»c viÃªn**
4. **ÄÃ¡nh giÃ¡ má»©c Ä‘á»™: X sao (tá»« 1 Ä‘áº¿n 5 sao, dÃ¹ng kÃ½ hiá»‡u â­ tÆ°Æ¡ng á»©ng)**

---
ğŸ“Œ TÃ¬nh huá»‘ng:
{scenario_text}

âœï¸ Pháº£n há»“i cá»§a há»c viÃªn:
{user_answer}

ğŸ“š TÃ i liá»‡u ná»™i bá»™:
1. {context_chunks[0]}
2. {context_chunks[1]}
3. {context_chunks[2]}
"""
    res = openai.chat.completions.create(
        model=OPENAI_MODEL,
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3,
        max_tokens=500
    )
    return res.choices[0].message.content.strip()

# --- Dá»± Ä‘oÃ¡n má»©c sao tá»« pháº£n há»“i GPT ---
def guess_star_rating(feedback_text):
    star_match = re.search(r"(\d)\s*sao", feedback_text.lower())
    if star_match:
        num = int(star_match.group(1))
        return "â­" * min(max(num, 1), 5)
    return "â­"  # fallback náº¿u khÃ´ng tÃ¬m tháº¥y

# --- TÃ¢m tráº¡ng pháº£n há»“i tÆ°Æ¡ng á»©ng vá»›i sá»‘ sao ---
def get_emotional_feedback(stars):
    mapping = {
        "â­â­â­â­â­": "ğŸŒŸ Tuyá»‡t vá»i! Báº¡n Ä‘Ã£ xá»­ lÃ½ ráº¥t tá»‘t, tiáº¿p tá»¥c phÃ¡t huy nhÃ©!",
        "â­â­â­â­": "ğŸ‘ KhÃ¡ tá»‘t! NhÆ°ng váº«n cÃ³ thá»ƒ chi tiáº¿t hÆ¡n.",
        "â­â­â­": "ğŸ˜ Báº¡n Ä‘Ã£ Ä‘i Ä‘Ãºng hÆ°á»›ng, cá»‘ gáº¯ng hoÃ n thiá»‡n hÆ¡n.",
        "â­â­": "âš ï¸ Báº¡n cÃ²n bá» sÃ³t nhiá»u bÆ°á»›c quan trá»ng.",
        "â­": "âŒ Cáº§n luyá»‡n táº­p ká»¹ hÆ¡n, Ä‘á»«ng lo â€“ cá»© tiáº¿p tá»¥c nhÃ©!"
    }
    return mapping.get(stars, "ğŸ™‚ Tiáº¿p tá»¥c nhÃ©!")

# --- Cáº¯t pháº§n hiá»ƒn thá»‹ Ä‘áº¿n mÃ´ táº£ triá»‡u chá»©ng thÃ´i ---
def extract_visible_part(scenario_text):
    cutoff = "Xá»­ lÃ½ táº¡i chá»—"
    parts = scenario_text.split(cutoff)
    return parts[0].strip() + "\n\nğŸ” Báº¡n sáº½ xá»­ lÃ½ tháº¿ nÃ o trong 3 phÃºt Ä‘áº§u tiÃªn?"

# --- Giao tiáº¿p Telegram ---
user_states = {}

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.message.from_user.id
    message_text = update.message.text.strip()
    lowered_text = message_text.lower()
    greetings = ["hi", "hello", "xin chÃ o", "chÃ o", "alo", "yo"]

    if user_id not in user_states or user_states[user_id]["status"] == "idle":
        scenario = pick_random_scenario()
        user_states[user_id] = {"status": "awaiting_response", "scenario": scenario}
        scenario_number = chunks.index(scenario) + 1
        visible = extract_visible_part(scenario)

        if lowered_text in greetings:
            await update.message.reply_text(
                "ğŸ‘‹ Xin chÃ o! TÃ´i lÃ  **Trá»£ lÃ½ Há»™i Nháº­p Äiá»u DÆ°á»¡ng**, nhiá»‡m vá»¥ cá»§a tÃ´i lÃ  há»— trá»£ báº¡n luyá»‡n pháº£n xáº¡ trong cÃ¡c tÃ¬nh huá»‘ng kháº©n cáº¥p thá»±c táº¿.\n\n"
                "BÃ¢y giá», hÃ£y báº¯t Ä‘áº§u vá»›i má»™t tÃ¬nh huá»‘ng Ä‘áº§u tiÃªn nhÃ©:"
            )
        else:
            await update.message.reply_text("ğŸ”” Báº¯t Ä‘áº§u kiá»ƒm tra tÃ¬nh huá»‘ng kháº©n cáº¥p Ä‘áº§u tiÃªn:")

        await update.message.reply_text(f"ğŸ§ª TÃ¬nh huá»‘ng {scenario_number:02d}:\n\n{visible}")
        return

    if user_states[user_id]["status"] == "awaiting_response":
        scenario = user_states[user_id]["scenario"]
        feedback = analyze_response(message_text, scenario)
        stars = guess_star_rating(feedback)
        emotion = get_emotional_feedback(stars)

        await update.message.reply_text(f"ğŸ“‹ ÄÃNH GIÃ CHáº¤T LÆ¯á»¢NG CÃ‚U TRáº¢ Lá»œI: \n\n{feedback}")
        #await update.message.reply_text(emotion)
        await update.message.reply_text("ğŸ”„ NÃ o, thÃªm má»™t tÃ¬nh huá»‘ng tiáº¿p theo nhÃ©:")

        next_scenario = pick_random_scenario()
        scenario_number = chunks.index(next_scenario) + 1
        visible = extract_visible_part(next_scenario)

        await update.message.reply_text(f"ğŸ§ª TÃ¬nh huá»‘ng {scenario_number:02d}:\n\n{visible}")
        user_states[user_id] = {"status": "awaiting_response", "scenario": next_scenario}
        return

# --- Web UI (náº¿u dÃ¹ng) ---
@flask_app.route("/", methods=["GET"])
def index():
    return render_template("index.html")

def run_flask():
    flask_app.run(host="0.0.0.0", port=int(os.environ.get("PORT", 10000)))

# --- Telegram bot khá»Ÿi Ä‘á»™ng ---
def main():
    TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
    if not TELEGRAM_TOKEN:
        print("âš ï¸ TELEGRAM_TOKEN chÆ°a Ä‘Æ°á»£c thiáº¿t láº­p!")
        return

    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.run_polling()

if __name__ == "__main__":
    threading.Thread(target=run_flask).start()
    main()
