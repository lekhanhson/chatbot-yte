import os
import random
import fitz  # PyMuPDF
import openai
from flask import Flask, render_template
from telegram import Update
from telegram.ext import ApplicationBuilder, ContextTypes, MessageHandler, filters
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import threading
import re

# --- Flask App ---
flask_app = Flask(__name__)

# --- OpenAI API Key ---
openai.api_key = os.getenv("OPENAI_API_KEY")
OPENAI_MODEL = "gpt-4-turbo"

# --- TÃ¡ch tá»«ng tÃ¬nh huá»‘ng tá»« PDF dá»±a vÃ o sá»‘ thá»© tá»± ---
def extract_cases_by_structure(path):
    doc = fitz.open(path)
    full_text = "\n".join([page.get_text() for page in doc])

    pattern = r'\n\d{1,2}\.\s'  # TÃ¡ch theo sá»‘ thá»© tá»± 1. 2. 3.
    parts = re.split(pattern, full_text)
    headers = re.findall(r'\n\d{1,2}\.\s', full_text)

    cases = []
    for i, part in enumerate(parts[1:], start=1):
        header = headers[i-1].strip()
        case_text = f"{header} {part}".strip()
        cases.append(case_text)
    return cases

# --- Load vÃ  xá»­ lÃ½ dá»¯ liá»‡u ---
chunks = extract_cases_by_structure("tinh_huong_khan_cap.pdf")
vectorizer = TfidfVectorizer()
chunk_vectors = vectorizer.fit_transform(chunks)

# --- Chá»n tÃ¬nh huá»‘ng báº¥t ká»³ ---
def pick_random_scenario():
    return random.choice(chunks)

# --- TÃ¬m Ä‘oáº¡n liÃªn quan Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ ---
def search_relevant_chunks(text, top_n=3):
    vec = vectorizer.transform([text])
    sims = cosine_similarity(vec, chunk_vectors).flatten()
    top_ids = sims.argsort()[-top_n:][::-1]
    return [chunks[i] for i in top_ids]

# --- PhÃ¢n tÃ­ch pháº£n há»“i cá»§a há»c viÃªn ---
def analyze_response(user_answer, scenario_text):
    context_chunks = search_relevant_chunks(scenario_text)
    prompt = f"""
Báº¡n lÃ  trá»£ lÃ½ Ä‘Ã o táº¡o Ä‘iá»u dÆ°á»¡ng. HÃ£y Ä‘Ã¡nh giÃ¡ pháº£n há»“i cá»§a há»c viÃªn dá»±a trÃªn tÃ¬nh huá»‘ng kháº©n cáº¥p vÃ  tÃ i liá»‡u hÆ°á»›ng dáº«n. HÃ£y phÃ¢n tÃ­ch:
1. CÃ¢u tráº£ lá»i cÃ³ phÃ¹ há»£p khÃ´ng?
2. Náº¿u chÆ°a Ä‘Ãºng thÃ¬ sai á»Ÿ Ä‘Ã¢u?
3. Gá»£i Ã½ vÃ  lÆ°u Ã½ thÃªm cho há»c viÃªn.

---  
ğŸ“Œ TÃ¬nh huá»‘ng:
{scenario_text}

âœï¸ Pháº£n há»“i cá»§a há»c viÃªn:
{user_answer}

ğŸ“š TÃ i liá»‡u ná»™i bá»™:
1. {context_chunks[0]}
2. {context_chunks[1]}
3. {context_chunks[2]}

Tráº£ lá»i:
"""
    res = openai.chat.completions.create(
        model=OPENAI_MODEL,
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3,
        max_tokens=500
    )
    return res.choices[0].message.content.strip()

# --- Giao tiáº¿p Telegram ---
user_states = {}

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.message.from_user.id
    message_text = update.message.text.strip()
    lowered_text = message_text.lower()

    greetings = ["hi", "hello", "xin chÃ o", "chÃ o", "alo", "yo"]

    if user_id not in user_states or user_states[user_id]["status"] == "idle":
        scenario = pick_random_scenario()
        user_states[user_id] = {"status": "awaiting_response", "scenario": scenario}

        scenario_number = chunks.index(scenario) + 1

        if lowered_text in greetings:
            await update.message.reply_text(
                "ğŸ‘‹ Xin chÃ o! TÃ´i lÃ  **Trá»£ lÃ½ Há»™i Nháº­p Äiá»u DÆ°á»¡ng**, nhiá»‡m vá»¥ cá»§a tÃ´i lÃ  há»— trá»£ báº¡n luyá»‡n pháº£n xáº¡ trong cÃ¡c tÃ¬nh huá»‘ng kháº©n cáº¥p thá»±c táº¿.\n\n"
                "BÃ¢y giá», hÃ£y báº¯t Ä‘áº§u vá»›i má»™t tÃ¬nh huá»‘ng Ä‘áº§u tiÃªn nhÃ©:"
            )
        else:
            await update.message.reply_text("ğŸ”” Báº¯t Ä‘áº§u kiá»ƒm tra tÃ¬nh huá»‘ng kháº©n cáº¥p Ä‘áº§u tiÃªn:")

        await update.message.reply_text(
            f"ğŸ§ª TÃ¬nh huá»‘ng {scenario_number:02d}:\n\n{scenario}\n\nğŸ‘‰ Báº¡n sáº½ xá»­ lÃ½ tháº¿ nÃ o trong 3 phÃºt Ä‘áº§u tiÃªn?"
        )
        return

    # Náº¿u Ä‘ang chá» cÃ¢u tráº£ lá»i
    if user_states[user_id]["status"] == "awaiting_response":
        scenario = user_states[user_id]["scenario"]
        feedback = analyze_response(message_text, scenario)

        await update.message.reply_text(f"ğŸ“‹ ÄÃ¡nh giÃ¡ tá»« trá»£ lÃ½:\n\n{feedback}")
        user_states[user_id]["status"] = "idle"
        return

# --- Web UI ---
@flask_app.route("/", methods=["GET"])
def index():
    return render_template("index.html")

def run_flask():
    flask_app.run(host="0.0.0.0", port=int(os.environ.get("PORT", 10000)))

# --- Cháº¡y Telegram Bot ---
def main():
    TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
    if not TELEGRAM_TOKEN:
        print("âš ï¸ TELEGRAM_TOKEN chÆ°a Ä‘Æ°á»£c thiáº¿t láº­p!")
        return

    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.run_polling()

if __name__ == "__main__":
    threading.Thread(target=run_flask).start()
    main()
