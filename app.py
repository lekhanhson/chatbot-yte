import os
import random
import fitz  # PyMuPDF
import openai
from flask import Flask, render_template
from telegram import Update
from telegram.ext import ApplicationBuilder, ContextTypes, MessageHandler, filters
import threading
import re
import asyncio

# --- Flask App ---
flask_app = Flask(__name__)

# --- OpenAI API ---
openai.api_key = os.getenv("OPENAI_API_KEY")
OPENAI_MODEL = "gpt-3.5-turbo"

# --- Load v√† x·ª≠ l√Ω PDF ---
def extract_scenarios_from_pdf(path, is_emergency=True):
    doc = fitz.open(path)
    full_text = "\n".join([page.get_text() for page in doc])
    pattern = r"T√¨nh hu·ªëng kh·∫©n c·∫•p\s+\d{1,2}:" if is_emergency else r"T√¨nh hu·ªëng giao ti·∫øp\s+\d+"
    parts = re.split(pattern, full_text)
    return [p.strip() for p in parts if p.strip()]

emergency_scenarios = extract_scenarios_from_pdf("tinh_huong_khan_cap.pdf", is_emergency=True)
communication_scenarios = extract_scenarios_from_pdf("tinh_huong_giao_tiep.pdf", is_emergency=False)

# --- Hi·ªÉn th·ªã n·ªôi dung t√¨nh hu·ªëng ---
def extract_visible_emergency(scenario):
    lines = scenario.split("\n")
    title = lines[0] if lines else "T√¨nh hu·ªëng kh·∫©n c·∫•p"
    desc = ""
    for line in lines[1:]:
        if line.lower().startswith("c·∫ßn th·ª±c hi·ªán"):
            break
        desc += line.strip() + " "
    return f"{title}\n{desc.strip()}\n\n üíó B·∫°n s·∫Ω x·ª≠ l√Ω th·∫ø n√†o?"

def extract_visible_communication(scenario):
    parts = scenario.split("ƒê√°p √°n:")
    question = parts[0].strip()
    return f"{question}\n\n üíó B·∫°n s·∫Ω x·ª≠ l√Ω th·∫ø n√†o?"

# --- ƒê√°nh gi√° b·∫±ng GPT ---
def analyze_response(user_answer, scenario_text, mode):
    prompt = f"""
B·∫°n l√† tr·ª£ l√Ω ƒë√†o t·∫°o ƒëi·ªÅu d∆∞·ª°ng. H√£y ƒë√°nh gi√° ph·∫£n h·ªìi c·ªßa h·ªçc vi√™n d·ª±a tr√™n t√¨nh hu·ªëng v√† ƒë∆∞a ra nh·∫≠n x√©t ng·∫Øn g·ªçn theo 2 m·ª•c:
1. M·ª©c ƒë·ªô ph√π h·ª£p c·ªßa c√¢u tr·∫£ l·ªùi: X (thay X b·∫±ng k√Ω hi·ªáu ‚≠ê, t·ª´ 1 ƒë·∫øn 5 ‚≠ê theo m·ª©c ƒë·ªô ph√π h·ª£p c·ªßa c√¢u tr·∫£ l·ªùi t·ª´ h·ªçc vi·ªán, sau ƒë√≥ gi·∫£i th√≠ch ng·∫Øn g·ªçn mang t√≠nh khuy·∫øn kh√≠ch)
2. ƒê√°p √°n t·ª´ t√†i li·ªáu: (sau ƒë√≥ tr√≠ch nguy√™n vƒÉn ƒë√°p √°n/c√°ch x·ª≠ l√Ω trong t√†i li·ªáu, kh√¥ng gi·∫£i th√≠ch th√™m b·ªõt t·ª´ g√¨)

---
üìå T√¨nh hu·ªëng:
{scenario_text}

‚úçÔ∏è Ph·∫£n h·ªìi c·ªßa h·ªçc vi√™n:
{user_answer}
"""
    res = openai.chat.completions.create(
        model=OPENAI_MODEL,
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2,
        max_tokens=500
    )
    return res.choices[0].message.content.strip()

# --- T√°ch sao t·ª´ GPT ---
def extract_star_rating(feedback_text):
    star_match = re.search(r"(\d)\s*sao", feedback_text.lower())
    if star_match:
        num = int(star_match.group(1))
        return min(max(num, 1), 5)
    return 1

# --- T√≥m t·∫Øt sau 4 l∆∞·ª£t ---
def summarize_feedback(star_list):
    avg = sum(star_list) / len(star_list)
    stars = "‚≠ê" * round(avg)
    if avg >= 4.5:
        msg = "B·∫°n th·ªÉ hi·ªán xu·∫•t s·∫Øc! Ti·∫øp t·ª•c gi·ªØ phong ƒë·ªô nh√©."
    elif avg >= 3.5:
        msg = "B·∫°n c√≥ n·ªÅn t·∫£ng t·ªët, h√£y luy·ªán t·∫≠p th√™m ƒë·ªÉ n√¢ng cao h∆°n n·ªØa."
    else:
        msg = "B·∫°n c·∫ßn luy·ªán th√™m ƒë·ªÉ n·∫Øm v·ªØng k·ªπ nƒÉng ph·∫£n x·∫°."
    return f"üéØ B·∫°n v·ª´a ho√†n th√†nh 4 t√¨nh hu·ªëng.\nƒêi·ªÉm trung b√¨nh: {stars}\n\nüí¨ Nh·∫≠n x√©t: {msg}"

# --- Qu·∫£n l√Ω tr·∫°ng th√°i ng∆∞·ªùi d√πng ---
user_states = {}

# --- T∆∞∆°ng t√°c Telegram ---
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.message.from_user.id
    text = update.message.text.strip()
    lowered_text = text.lower()

    greetings = ["hi", "hello", "xin ch√†o", "ch√†o", "alo", "yo", "chao", "/start"]
    affirm = ["ok", "oki", "c√≥", "yes"]
    deny = ["kh√¥ng", "ko", "no"]

    if user_id not in user_states:
        user_states[user_id] = {
            "mode": "emergency",
            "status": "idle",
            "scenario": None,
            "history": [],
            "awaiting_continue": False
        }

    state = user_states[user_id]

    if state["awaiting_continue"]:
        if lowered_text in affirm:
            state.update({"awaiting_continue": False, "history": []})
            state["status"] = "idle"
            await update.message.reply_text("üëç Tuy·ªát v·ªùi! Ch√∫ng ta ti·∫øp t·ª•c luy·ªán nh√©!")
            return
        elif lowered_text in deny:
            await update.message.reply_text("‚è≥ M√¨nh s·∫Ω ch·ªù 30 gi√¢y r·ªìi h·ªèi l·∫°i nh√©...")
            await asyncio.sleep(30)
            await update.message.reply_text("üîÅ B·∫°n c√≥ mu·ªën ti·∫øp t·ª•c luy·ªán t·∫≠p kh√¥ng? (ok / kh√¥ng)")
            return
        else:
            await update.message.reply_text("‚ùì M√¨nh ch∆∞a r√µ. B·∫°n c√≥ mu·ªën ti·∫øp t·ª•c luy·ªán t·∫≠p kh√¥ng? (ok / kh√¥ng)")
            return

    if state["status"] == "idle":
        mode = state["mode"]
        scenario = random.choice(emergency_scenarios) if mode == "emergency" else random.choice(communication_scenarios)
        visible_text = extract_visible_emergency(scenario) if mode == "emergency" else extract_visible_communication(scenario)

        if lowered_text in greetings:
            await update.message.reply_text("üëã Xin ch√†o! T√¥i l√† TR·ª¢ L√ù AI \n[B·ªánh Vi·ªán ƒêa khoa L√¢m Hoa].\n\nCh√∫ng ta s·∫Ω c√πng luy·ªán ph·∫£n x·∫° t√¨nh hu·ªëng ƒëi·ªÅu d∆∞·ª°ng.\nB·∫Øt ƒë·∫ßu v·ªõi t√¨nh hu·ªëng ƒë·∫ßu ti√™n nh√©!")
            await asyncio.sleep(1)

        await update.message.reply_text(f"{'üî• T√¨nh hu·ªëng KH·∫®N C·∫§P' if mode == 'emergency' else 'üí¨ T√¨nh hu·ªëng GIAO TI·∫æP'}\n\n{visible_text}")
        state.update({"scenario": scenario, "status": "awaiting_response"})
        return

    if state["status"] == "awaiting_response":
        scenario = state["scenario"]
        mode = state["mode"]

        # G·ª≠i ph·∫£n h·ªìi GPT ƒë√°nh gi√° c√¢u tr·∫£ l·ªùi
        feedback = analyze_response(text, scenario, mode)
        stars = extract_star_rating(feedback)
        state["history"].append(stars)  # l∆∞u l·∫°i ƒëi·ªÉm s·ªë

        await update.message.reply_text(f"üìã NH·∫¨N X√âT T·ª™ TR·ª¢ L√ù AI:n\n\n{feedback}")

        # N·∫øu ƒë√£ tr·∫£ l·ªùi ƒë·ªß 4 t√¨nh hu·ªëng th√¨ t·ªïng k·∫øt v√† h·ªèi ti·∫øp t·ª•c
        if len(state["history"]) >= 4:
            await update.message.reply_text("üôè C·∫£m ∆°n b·∫°n, ch√∫ng ta ƒë√£ luy·ªán t·∫≠p 4 t√¨nh hu·ªëng, c√πng nh√¨n l·∫°i nh√©!")
            summary = summarize_feedback(state["history"])
            await update.message.reply_text(summary)
            await update.message.reply_text("üîÅ B·∫°n c√≥ mu·ªën ti·∫øp t·ª•c luy·ªán t·∫≠p kh√¥ng? (ok / kh√¥ng)")
            state["awaiting_continue"] = True
            return  # üîÅ D·ª´ng t·∫°i ƒë√¢y, kh√¥ng g·ª≠i ti·∫øp t√¨nh hu·ªëng m·ªõi

        # N·∫øu ch∆∞a ƒë·ªß 4 t√¨nh hu·ªëng th√¨ g·ª≠i ti·∫øp
        next_mode = "communication" if mode == "emergency" else "emergency"
        next_scenario = random.choice(emergency_scenarios) if next_mode == "emergency" else random.choice(communication_scenarios)
        next_text = extract_visible_emergency(next_scenario) if next_mode == "emergency" else extract_visible_communication(next_scenario)

        await update.message.reply_text(f"{'üî• T√¨nh hu·ªëng KH·∫®N C·∫§P' if next_mode == 'emergency' else 'üí¨ T√¨nh hu·ªëng GIAO TI·∫æP'}\n\n{next_text}")

        # C·∫≠p nh·∫≠t tr·∫°ng th√°i cho l·∫ßn ti·∫øp theo
        state.update({"mode": next_mode, "scenario": next_scenario, "status": "awaiting_response"})
        return

@flask_app.route("/", methods=["GET"])
def index():
    return render_template("index.html")

def run_flask():
    flask_app.run(host="0.0.0.0", port=int(os.environ.get("PORT", 10000)))

def main():
    TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
    if not TELEGRAM_TOKEN:
        print("‚ö†Ô∏è TELEGRAM_TOKEN ch∆∞a ƒë∆∞·ª£c thi·∫øt l·∫≠p!")
        return

    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.run_polling()

if __name__ == "__main__":
    threading.Thread(target=run_flask).start()
    main()
